{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/hgfer/OneDrive/Documentos/Notebooks/TMDB Box Office Prediction/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/hgfer/OneDrive/Documentos/Notebooks/TMDB Box Office Prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the information of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      "id                       3000 non-null int64\n",
      "belongs_to_collection    604 non-null object\n",
      "budget                   3000 non-null int64\n",
      "genres                   2993 non-null object\n",
      "homepage                 946 non-null object\n",
      "imdb_id                  3000 non-null object\n",
      "original_language        3000 non-null object\n",
      "original_title           3000 non-null object\n",
      "overview                 2992 non-null object\n",
      "popularity               3000 non-null float64\n",
      "poster_path              2999 non-null object\n",
      "production_companies     2844 non-null object\n",
      "production_countries     2945 non-null object\n",
      "release_date             3000 non-null object\n",
      "runtime                  2998 non-null float64\n",
      "spoken_languages         2980 non-null object\n",
      "status                   3000 non-null object\n",
      "tagline                  2403 non-null object\n",
      "title                    3000 non-null object\n",
      "Keywords                 2724 non-null object\n",
      "cast                     2987 non-null object\n",
      "crew                     2984 non-null object\n",
      "revenue                  3000 non-null int64\n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4398 entries, 0 to 4397\n",
      "Data columns (total 22 columns):\n",
      "id                       4398 non-null int64\n",
      "belongs_to_collection    877 non-null object\n",
      "budget                   4398 non-null int64\n",
      "genres                   4382 non-null object\n",
      "homepage                 1420 non-null object\n",
      "imdb_id                  4398 non-null object\n",
      "original_language        4398 non-null object\n",
      "original_title           4398 non-null object\n",
      "overview                 4384 non-null object\n",
      "popularity               4398 non-null float64\n",
      "poster_path              4397 non-null object\n",
      "production_companies     4140 non-null object\n",
      "production_countries     4296 non-null object\n",
      "release_date             4397 non-null object\n",
      "runtime                  4394 non-null float64\n",
      "spoken_languages         4356 non-null object\n",
      "status                   4396 non-null object\n",
      "tagline                  3535 non-null object\n",
      "title                    4395 non-null object\n",
      "Keywords                 4005 non-null object\n",
      "cast                     4385 non-null object\n",
      "crew                     4376 non-null object\n",
      "dtypes: float64(2), int64(2), object(18)\n",
      "memory usage: 756.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7398 entries, 0 to 7397\n",
      "Data columns (total 22 columns):\n",
      "id                       7398 non-null int64\n",
      "belongs_to_collection    1481 non-null object\n",
      "budget                   7398 non-null int64\n",
      "genres                   7375 non-null object\n",
      "homepage                 2366 non-null object\n",
      "imdb_id                  7398 non-null object\n",
      "original_language        7398 non-null object\n",
      "original_title           7398 non-null object\n",
      "overview                 7376 non-null object\n",
      "popularity               7398 non-null float64\n",
      "poster_path              7396 non-null object\n",
      "production_companies     6984 non-null object\n",
      "production_countries     7241 non-null object\n",
      "release_date             7397 non-null object\n",
      "runtime                  7392 non-null float64\n",
      "spoken_languages         7336 non-null object\n",
      "status                   7396 non-null object\n",
      "tagline                  5938 non-null object\n",
      "title                    7395 non-null object\n",
      "Keywords                 6729 non-null object\n",
      "cast                     7372 non-null object\n",
      "crew                     7360 non-null object\n",
      "dtypes: float64(2), int64(2), object(18)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#dropping the feature revenue from the train dataset\n",
    "train_drop  = train.drop(columns =['revenue'])\n",
    "\n",
    "#separting the output data from the train dataset\n",
    "y = train.revenue\n",
    "\n",
    "#getting the size of the train dataset\n",
    "n_train = train.shape[0]\n",
    "\n",
    "#putting the both datasets together\n",
    "all_data = pd.concat((train_drop , test), sort = False).reset_index(drop = True)\n",
    "\n",
    "#info from the new dataset\n",
    "all_data.info()\n",
    "\n",
    "#value used top check the most common values in a feature\n",
    "top_value = 10\n",
    "\n",
    "#dropping unusual features\n",
    "#all_data = all_data.drop(columns = ['id','imdb_id','original_title','title'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Belongs to Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put 1 in the movies that have collection and 0 in ones that don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the movie has collection\n",
    "all_data['has_collection'] = all_data['belongs_to_collection'].apply(lambda x: 1 if str(x) != 'nan' else 0)\n",
    "\n",
    "#dropping belongs to collection\n",
    "all_data = all_data.drop(columns = ['belongs_to_collection'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column for each genre\n",
    "list_genres = all_data['genres'].apply(lambda x: [i['name'] for i in eval(x)] if str(x) != 'nan' else 0)\n",
    "\n",
    "#top 10 genres\n",
    "top_genre = list(dict(Counter(list_genres.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for genre in top_genre:\n",
    "    all_data['genre_' + genre] = all_data['genres'].apply(lambda x: 1 if genre in str(x) else 0)\n",
    "\n",
    "#dropping genres\n",
    "all_data = all_data.drop(columns = ['genres'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the movie has homepage\n",
    "all_data['has_homepage'] = all_data['homepage'].apply(lambda x: 1 if str(x) != 'nan' else 0)\n",
    "\n",
    "#dropping homepage\n",
    "all_data = all_data.drop(columns = ['homepage'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Original Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column for each original language\n",
    "all_data = pd.get_dummies(all_data, columns = ['original_language'], drop_first = True, prefix = 'original_language')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the movie has overview\n",
    "all_data['has_overview'] = all_data['overview'].apply(lambda x: 1 if str(x) != 'nan' else 0)\n",
    "\n",
    "#dropping overview\n",
    "all_data = all_data.drop(columns = ['overview'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Poster Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the movie has poster path\n",
    "all_data['has_poster_path'] = all_data['poster_path'].apply(lambda x: 1 if str(x) != 'nan' else 0)\n",
    "\n",
    "#dropping poster path\n",
    "all_data = all_data.drop(columns = ['poster_path'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Production Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the production companies.\n",
    "#Nan it's a movie that doesn't have production company\n",
    "list_companies = all_data['production_companies'].apply(lambda x: [i['name'] for i in eval(x)] if str(x) != 'nan' else \"nan\")\n",
    "\n",
    "#top 10 production company\n",
    "top_companies = list(dict(Counter(list_companies.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for company in top_companies:\n",
    "    all_data['production_company_' + company] = all_data['production_companies'].apply(lambda x: 1 if company in str(x) else 0)\n",
    "\n",
    "#droping production companies\n",
    "all_data = all_data.drop(columns = ['production_companies'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Production Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the production coutries\n",
    "#Nan it's a movie that doesn't have production country\n",
    "list_countries = all_data['production_countries'].apply(lambda x: [i['name'] for i in eval(x)] if str(x) != 'nan' else \"nan\")\n",
    "\n",
    "#top 10 production countries\n",
    "top_countries = list(dict(Counter(list_countries.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for country in top_countries:\n",
    "    all_data['production_country_' + country] = all_data['production_countries'].apply(lambda x: 1 if country in str(x) else 0)\n",
    "\n",
    "#dropping production countries\n",
    "\n",
    "all_data = all_data.drop(columns = ['production_countries'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Release Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['release_date'] = pd.to_datetime(all_data.release_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10.Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the nan values with the mean\n",
    "all_data['runtime'].fillna(all_data.runtime.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Spoken Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column for each spoken language\n",
    "#Nan it's a movie that doesn't have spoken language\n",
    "list_languages = all_data['spoken_languages'].apply(lambda x: [i['iso_639_1'] for i in eval(x)] if str(x) != 'nan' else 'nan')\n",
    "\n",
    "#top 10 spoken languages\n",
    "top_languages = list(dict(Counter(list_languages.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for language in top_languages:\n",
    "    all_data['spoken_language_' + language] = all_data['spoken_languages'].apply(lambda x: 1 if language in str(x) else 0)\n",
    "\n",
    "\n",
    "#dropping spoken languages\n",
    "all_data = all_data.drop(columns = ['spoken_languages'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data, columns = ['status'], drop_first = True, prefix = 'status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 Tagline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the movie has tagline\n",
    "all_data['has_tagline'] = all_data['tagline'].apply(lambda x: 1 if str(x) != 'nan' else 0)\n",
    "\n",
    "#dropping poster path\n",
    "all_data = all_data.drop(columns = ['tagline'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.14 Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the keywords\n",
    "list_keywords = all_data['Keywords'].apply(lambda x: [i['name'] for i in eval(x)] if str(x) != 'nan' else 'nan')\n",
    "\n",
    "#top 10 keywords\n",
    "top_keywords = list(dict(Counter(list_keywords.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for keyword in top_keywords:\n",
    "    all_data['keyword_' + keyword] = all_data['Keywords'].apply(lambda x: 1 if keyword in str(x) else 0)\n",
    "\n",
    "#droping Keywords\n",
    "all_data = all_data.drop(columns = ['Keywords'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.15 Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the number of actors in each gender\n",
    "all_data['cast_gender_0'] = all_data['cast'].apply(lambda x: [i['gender'] == 0 for i in eval(x)].count(True)  if str(x) != 'nan' else 0)\n",
    "all_data['cast_gender_1'] = all_data['cast'].apply(lambda x: [i['gender'] == 1 for i in eval(x)].count(True)  if str(x) != 'nan' else 0)\n",
    "all_data['cast_gender_2'] = all_data['cast'].apply(lambda x: [i['gender'] == 2 for i in eval(x)].count(True)  if str(x) != 'nan' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the cast name\n",
    "list_cast_names = all_data['cast'].apply(lambda x: [i['name'] for i in eval(x)] if str(x) != 'nan' else 'nan')\n",
    "\n",
    "#top 10 cast name\n",
    "top_cast_names = list(dict(Counter(list_cast_names.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for name in top_cast_names:\n",
    "    all_data['cast_name_' + name] = all_data['cast'].apply(lambda x: 1 if name in str(x) else 0)\n",
    "    \n",
    "#droping cast\n",
    "all_data = all_data.drop(columns = ['cast'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.16 Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the number of actors in each gender\n",
    "all_data['crew_gender_0'] = all_data['crew'].apply(lambda x: [i['gender'] == 0 for i in eval(x)].count(True)  if str(x) != 'nan' else 0)\n",
    "all_data['crew_gender_1'] = all_data['crew'].apply(lambda x: [i['gender'] == 1 for i in eval(x)].count(True)  if str(x) != 'nan' else 0)\n",
    "all_data['crew_gender_2'] = all_data['crew'].apply(lambda x: [i['gender'] == 2 for i in eval(x)].count(True)  if str(x) != 'nan' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the crew name\n",
    "list_crew_names = all_data['crew'].apply(lambda x: [i['name'] for i in eval(x)] if str(x) != 'nan' else 'nan')\n",
    "\n",
    "#top 10 crew name\n",
    "top_crew_names = list(dict(Counter(list_crew_names.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for crew_name in top_crew_names:\n",
    "    all_data['crew_name_' + crew_name] = all_data['crew'].apply(lambda x: 1 if crew_name in str(x) else 0)\n",
    "    \n",
    "#getting the crew department\n",
    "list_crew_departments = all_data['crew'].apply(lambda x: [i['department'] for i in eval(x)] if str(x) != 'nan' else 'nan')\n",
    "\n",
    "#top 10 crew_departments\n",
    "top_crew_departments = list(dict(Counter(list_crew_departments.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for crew_department in top_crew_departments:\n",
    "    all_data['crew_department_' + crew_department] = all_data['crew'].apply(lambda x: 1 if crew_department in str(x) else 0)\n",
    "\n",
    "#getting the crew name\n",
    "list_crew_jobs = all_data['crew'].apply(lambda x: [i['job'] for i in eval(x)] if str(x) != 'nan' else 'nan')\n",
    "\n",
    "#top 10 jobs\n",
    "top_crew_jobs = list(dict(Counter(list_crew_jobs.apply(pd.Series).stack()).most_common(top_value)).keys())\n",
    "for jobs in top_crew_jobs:\n",
    "    all_data['crew_job_' + jobs] = all_data['crew'].apply(lambda x: 1 if jobs in str(x) else 0)    \n",
    "    \n",
    "#droping crew\n",
    "all_data = all_data.drop(columns = ['crew'], axis = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
